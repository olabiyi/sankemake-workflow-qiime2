sample_file: "config/sample.tsv"
metadata: "00.mapping/metadata.tsv"
mail: "obadbotanist@yahoo.com" # A mere label
samples: ["A1", "A2", "A3", "A4", "A5", "A6", "A7", "A8", "A9", "A10", 
          "B1", "B2", "B3", "B4", "B5", "B6", "B7", "B8", "B9_1", "B9_2",
          "B10_1", "B10_2", "C1", "C2", "C3", "C4", "C5", "C6", "C7", 
          "C8", "D1", "D2", "D3", "D4", "D5", "D6", "D7", "D8", "D9", 
          "D10", "E1", "E2", "E3", "E4", "E5", "E6", "E7", "E8", "E9",
          "E10", "F1", "F2", "F3", "F4", "F5", "F6", "F7", "F8", "F9", 
          "F10", "G1", "G2", "G3", "G4", "G5", "G6", "G7", "G8", "G9", "G10"]
 # List your sample names here - see the README.md file for an easy way to create this list
project_dir: "/scratch/user/obayomi/projects/Zebrafish/16S_trimmed_unmerged"
# what type of amplicon are we analyzing
# options are
# "16S", "18S" and "ITS"
amplicon: "16S" # "ITS" 
# A coloumn in metada for grouping bar plot and for statistics
category: "Treatment"
# Three possible mode
# pair - paired-end reads without joining
# single - single end reads, joining of unnecessary
# merge - merge paired end reads
# if you will select to join the reads 
# # make sure to modify the -m -t flags of pear in the run_pear.pl script 
# before running the workflow

mode: "pair" # "pair", "single" or "merge"
RENAME_FILES: false # should your input files be renamed if they don't follow the requirement of 01.raw_data/{SAMPLE}_R{1|2}.fastq.gz

# What method should be used in merging reads
# options are "pear" or "vsearch"
# for merging with pear or vsearch, repectively
merge_method: "pear"

# ASV or zoTUs denoising and clustering method. Can be "dada2" or "deblur"
denoise_method: "dada2"

# path to your manifest file - see the example folder for examples
MANIFEST:  "01.raw_data/MANIFEST"
project_name: "Zebrafish" # This has no use in the pipeline just help to keep records

# # Add this line to everdy script to avoid device out of space error
TEMP_DIR: "export TEMPDIR=/scratch/user/obayomi/projects/Zebrafish/tmp/ TMPDIR=/scratch/user/obayomi/projects/Zebrafish/tmp/"

# set the path to the appropriate classifier for assigning taxonomy
# Here i chose the classifier for silva for bacteria (16S) and protist (18S) analysis
# For Fungi set to the path of a pre trained unite database classifier
classifier:  "/scratch/user/obayomi/projects/qiime2/create_DB/databases/silva-138-99-nb-classifier.qza"

# To figure out the total number of sequences ("Total freqency") 
# to be used to determine the minuminum frequency for filtering out
# rare taxa, examine "08.Filter_feature_table/taxa_filtered_table.qzv".
# To calculate, multiply the total number of sequences by 0.00005 (0.005%)
# Assign the result of your calulation below as the minimum frequency 
# for filtering out rare taxa
# 741,904 * 0.00005 = 37.0952
minimum_frequency: 37

# Change this and re-run core diversity step if needed. Determine this number by
# examiming "08.Filter_feature_table/filtered_table.qzv". Either choose the
# minimum sequence count or choose the minimum sequence count 
# that will be enough to capture the diversity of your samples and still
# not lose a lot of samples
rarefaction_depth: 123


# Full paths to the specified programs
programs_path:
    multiqc: "/scratch/user/obayomi/.conda/envs/bioinfo/bin/multiqc"
    fastqc: "/scratch/user/obayomi/.conda/envs/bioinfo/bin/fastqc"
    parallel: "/scratch/user/obayomi/.conda/envs/bioinfo/bin/parallel"
    run_pear:  "pear" #"/scratch/user/obayomi/projects/qiime2/run_pear.pl"

# Set tool specific parameters
parameters:
    vsearch:
        join_pairs:
            truncqual: 20
            minimum_length: 400
            maximum_Ns: 20
            minimum_merge_length: 400
            minimum_merge_length: 600
    dada2:
        mode: "single" # "single" or "paired"
        trunc_length_forward: 200 # 280 #220 # this will be determined after visulaizing the quality plot where quality score is >= 20
        trunc_length_reverse: 140 #180
        trim_length_forward: 0
        trim_length_reverse: 0
        maximum_forward_error: 4
        maximum_reverse_error: 4
        threads: 28

    # --p-trim-length n which truncates the sequences at position n
    # In general, the Deblur developers recommend setting this value
    # to a length where the median quality score begins to drop too low 
    deblur:
        trunc_length: 40
    # Parameters to argument of qiime feature-table group
    # when grouping the feature table for making grouped taxa barplots
    group_taxa_plot:
        category: "Treatment" # --m-metadata-column argument
        mode: "sum" # --p-mode argument
        metadata: "00.mapping/treatment-metadata.tsv" # a 2-column or more metadata for grouping bar plots ['sample-id', 'treatment']
    beta_diversity_significance:
         categories: "Treatment" 
   # Adators and primer trimming using cutadapt
    cutadapt:
        forward_primer: "GTGYCAGCMGCCGCGGTAA"
        reverse_primer: "GGACTACNVGGGTWTCTAAT"
        cores: 10
    fastree:
        threads: 28
    assign_taxonomy:
        threads: 28
    picrust:
        threads: 28
    pear:
        min_assembly: 150
        max_assembly: 300
        min_trim: 150
        threads: 8

conda:
    qiime2:
        env: "module purge; module load Anaconda3/2020.07; source activate /sw/hprc/sw/Anaconda3/2020.07/envs/qiime2-2021.2"
        perl5lib: "export PERL5LIB=/sw/hprc/sw/Anaconda3/2020.07/envs/qiime2-2021.2/lib/site_perl/5.26.2/x86_64-linux-thread-multi"
    picrust2:
        env: "module purge; module load Anaconda3/2020.07; source activate /scratch/user/obayomi/.conda/envs/picrust2"
        perl5lib: "export PERL5LIB=/scratch/user/obayomi/.conda/envs/picrust2/lib/site_perl/5.26.2/x86_64-linux-thread-multi"
    bioinfo:
        env: "module purge; module load Anaconda3/2020.07; source activate /scratch/user/obayomi/.conda/envs/bioinfo"
        perl5lib: "export PERL5LIB=/scratch/user/obayomi/.conda/envs/bioinfo/lib/5.26.2"
    pear:
        env: "module purge; module load GCCcore/9.3.0 PEAR/0.9.11"

